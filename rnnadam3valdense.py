# -*- coding: utf-8 -*-
"""RNNadam3valDense.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11OYQc3ZyIe-D0MPNoghV66jWLRz1JK9k
"""

from google.colab import drive
drive.mount('/content/drive')

import csv
from os import write
from keras.layers import Dropout
from keras.layers import LSTM
from keras.layers import Dense
from keras.models import Sequential
from sklearn.preprocessing import MinMaxScaler
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from tensorflow.keras.models import load_model

# Importing the training set

dataset_train = pd.read_csv('/content/drive/MyDrive/Estee/TrainingData.csv')
training_set = dataset_train.iloc[:, 1:].values

# Feature Scaling
sc = MinMaxScaler(feature_range=(0, 1))
training_set_scaled = sc.fit_transform(training_set)

# Creating a data structure with 60 timesteps and 1 output
X_train = []
y_train = []
for i in range(60, len(training_set)):
    X_train.append(training_set_scaled[i-60:i,])
    y_train.append(training_set_scaled[i, 0])
X_train, y_train = np.array(X_train), np.array(y_train)

# Reshaping
X_train = np.reshape(
    X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))

# Part 2 - Building the RNN
regressor = Sequential()


# Adding the first LSTM layer and some Dropout regularisation
regressor.add(LSTM(units=168, return_sequences=True,
                   input_shape=(X_train.shape[1], X_train.shape[2])))
regressor.add(Dropout(0.2))

# Adding a second LSTM layer and some Dropout regularisation
regressor.add(LSTM(units=168, return_sequences=True))
regressor.add(Dropout(0.2))

# Adding a third LSTM layer and some Dropout regularisation
regressor.add(LSTM(units=168, return_sequences=True))
regressor.add(Dropout(0.2))

# Adding a fourth LSTM layer and some Dropout regularisation
regressor.add(LSTM(units=168))
regressor.add(Dropout(0.2))

# Adding the output layer
regressor.add(Dense(units=112, kernel_initializer = 'uniform', activation = 'linear', input_dim = 168))

# Adding the output layer
regressor.add(Dense(units=1))

# Compiling the RNN
regressor.compile(optimizer='adam', loss='mean_squared_error')

# Fitting the RNN to the Training set
regressor.fit(X_train, y_train, epochs=150, batch_size=32,validation_split=0.33)

# Saving The Model
regressor.save('/content/drive/MyDrive/Estee/MyModeladam3val150Dense.hd5')
del X_train
del y_train

# Getting the test data
dataset_test = pd.read_csv('/content/drive/MyDrive/Estee/TestingData.csv')
test_set=dataset_test.iloc[:,1:].values
test_set = np.concatenate((np.zeros((len(test_set), 1)), test_set), axis=1)
dataset_l6 = dataset_train[len(dataset_train)-60:]
test_l6=dataset_l6.iloc[:, 1:].values
inputs = np.concatenate((test_l6, test_set), axis=0)

# Padding input for Same Scale Transformation
# input_padded = np.concatenate((np.zeros((len(inputs), 1)), inputs), axis=1)
# inputs = sc.transform(input_padded)
# inputs = input_padded[:, 1:]
# del input_padded
inputs = sc.transform(inputs)

# Test Data Structure
X_test = []
from tqdm import tqdm
for i in tqdm(range(60, len(inputs))):
    pred=regressor.predict(np.array([inputs[i-60:i]]))
    inputs[i,0]=pred
    # print(i,end=',')


inputs=sc.inverse_transform(inputs)

# Test Prediction

attributes = ["Id", "Predicted"]
with open('/content/drive/MyDrive/Estee/MyResadam3val150Dense.csv', 'w+', newline='') as wr:
  writer = csv.writer(wr)
  writer.writerow(attributes)
  for i in range(60,len(inputs)):
    writer.writerow([i+1-60, inputs[i,0]])

# # Padding Predictions for Inverse Transformation
# pad = np.zeros((len(predicted_stock_price), X_test.shape[2]))
# predicted_stock_price_padded = np.concatenate(
#     (predicted_stock_price, pad), axis=1)
# predicted_stock_price_padded = sc.inverse_transform(
#     predicted_stock_price_padded)
# predicted_stock_price = predicted_stock_price_padded[:, 0]
# del predicted_stock_price_padded

# # Writing Data
# attributes = ["Id", "Predicted"]
# with open('/content/drive/MyDrive/Estee/MyResadam 168.csv', 'w+', newline='') as wr:
#     writer = csv.writer(wr)
#     writer.writerow(attributes)
#     for i in range(len(predicted_stock_price)):
#         writer.writerow([i+1, predicted_stock_price[i]])

